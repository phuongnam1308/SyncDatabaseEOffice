const logger = require('../../utils/logger');
const StreamOutgoingMigrationModel = require('./StreamOutgoingMigrationModel');

/**
 * StreamOutgoingMigrationService
 * 
 * Service t·ªïng h·ª£p t·∫•t c·∫£ logic migration vƒÉn b·∫£n ƒëi
 * X·ª≠ l√Ω batch processing v√† insert tr·ª±c ti·∫øp v√†o DB m·ªõi
 * Kh√¥ng s·ª≠ d·ª•ng b·∫£ng trung gian
 * 
 * Quy tr√¨nh:
 * 1. L·∫•y batch t·ª´ DB c≈©
 * 2. Map v√† clean data
 * 3. Insert/Update v√†o DB m·ªõi
 * 4. L·∫∑p l·∫°i cho ƒë·∫øn khi h·∫øt data
 */
class StreamOutgoingMigrationService {
  
  constructor() {
    this.model = null;
    this.defaultBatchSize = 100;
  }

  /**
   * Kh·ªüi t·∫°o model
   */
  async initialize() {
    try {
      this.model = new StreamOutgoingMigrationModel();
      await this.model.initialize();
      logger.info('[StreamOutgoingMigrationService] Initialized successfully');
    } catch (error) {
      logger.error('[StreamOutgoingMigrationService] Initialize error:', error);
      throw new Error(`Kh√¥ng th·ªÉ kh·ªüi t·∫°o service: ${error.message}`);
    }
  }

  /**
   * L·∫•y tr·∫°ng th√°i migration hi·ªán t·∫°i
   * @returns {Promise<Object>} Th√¥ng tin tr·∫°ng th√°i
   */
  async getStatus() {
    try {
      if (!this.model) {
        throw new Error('Service ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o');
      }

      const status = await this.model.getStatus();
      
      return {
        totalInOldDb: status.totalInOldDb || 0,
        totalInNewDb: status.totalInNewDb || 0,
        remaining: status.remaining || 0,
        lastMigratedId: status.lastMigratedId || null
      };
    } catch (error) {
      logger.error('[StreamOutgoingMigrationService.getStatus] Error:', error);
      throw error;
    }
  }

  /**
   * Th·ª±c hi·ªán migration theo batch
   * 
   * @param {Object} options - T√πy ch·ªçn migration
   * @param {number} options.limit - T·ªïng s·ªë b·∫£n ghi c·∫ßn migrate (0 = t·∫•t c·∫£)
   * @param {number} options.batch - S·ªë l∆∞·ª£ng b·∫£n ghi m·ªói batch
   * @returns {Promise<Object>} K·∫øt qu·∫£ migration
   */
  async migrate({ limit = 0, batch = this.defaultBatchSize }) {
    const startTime = Date.now();
    
    // Validate
    if (!this.model) {
      throw new Error('Service ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o. G·ªçi initialize() tr∆∞·ªõc.');
    }

    if (batch <= 0) {
      throw new Error('Batch size ph·∫£i l·ªõn h∆°n 0');
    }

    if (limit < 0) {
      throw new Error('Limit kh√¥ng ƒë∆∞·ª£c √¢m');
    }

    logger.info('='.repeat(80));
    logger.info(`[StreamOutgoingMigrationService] B·∫ÆT ƒê·∫¶U MIGRATION`);
    logger.info(`‚îú‚îÄ Limit: ${limit || 'ALL'}`);
    logger.info(`‚îú‚îÄ Batch Size: ${batch}`);
    logger.info('='.repeat(80));

    let totalInserted = 0;
    let totalUpdated = 0;
    let totalProcessed = 0;
    let batchCount = 0;
    let hasMore = true;
    let lastProcessedId = null;

    try {
      while (hasMore) {
        batchCount++;
        const batchStartTime = Date.now();

        logger.info('');
        logger.info(`‚îå‚îÄ BATCH ${batchCount} ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ`);
        
        try {
          // === B∆Ø·ªöC 1: L·∫§Y D·ªÆ LI·ªÜU T·ª™ DB C≈® ===
          logger.info(`‚îÇ  üì• Fetching ${batch} records from OLD DB...`);
          const oldRecords = await this.model.fetchBatchFromOldDb({
            batch,
            lastId: lastProcessedId
          });

          if (!oldRecords || oldRecords.length === 0) {
            logger.info(`‚îÇ  ‚ÑπÔ∏è  No more records to process`);
            hasMore = false;
            break;
          }

          logger.info(`‚îÇ  ‚úì Fetched ${oldRecords.length} records`);

          // === B∆Ø·ªöC 2: MAP V√Ä CLEAN DATA ===
          logger.info(`‚îÇ  üîÑ Mapping and cleaning data...`);
          const mappedRecords = await this.model.mapAndCleanBatch(oldRecords);
          logger.info(`‚îÇ  ‚úì Mapped ${mappedRecords.length} records`);

          // === B∆Ø·ªöC 3: INSERT/UPDATE V√ÄO DB M·ªöI ===
          logger.info(`‚îÇ  üíæ Inserting/Updating to NEW DB...`);
          const batchResult = await this.model.insertBatchToNewDb(mappedRecords);
          
          const inserted = batchResult.inserted || 0;
          const updated = batchResult.updated || 0;
          
          totalInserted += inserted;
          totalUpdated += updated;
          totalProcessed += oldRecords.length;

          // Update last processed ID
          if (oldRecords.length > 0) {
            lastProcessedId = oldRecords[oldRecords.length - 1].ID;
          }

          const batchDuration = ((Date.now() - batchStartTime) / 1000).toFixed(2);
          
          logger.info(`‚îÇ  ‚úì Inserted: ${inserted}, Updated: ${updated}`);
          logger.info(`‚îÇ  ‚è±Ô∏è  Batch duration: ${batchDuration}s`);
          logger.info(`‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ`);

          // === KI·ªÇM TRA LIMIT ===
          if (limit > 0 && totalProcessed >= limit) {
            logger.info('');
            logger.info(`‚ö†Ô∏è  Reached limit (${limit}). Stopping...`);
            hasMore = false;
            break;
          }

          // === KI·ªÇM TRA XEM C√ì BATCH TI·∫æP THEO KH√îNG ===
          if (oldRecords.length < batch) {
            logger.info('');
            logger.info(`‚ÑπÔ∏è  Last batch (received ${oldRecords.length} < ${batch}). Stopping...`);
            hasMore = false;
            break;
          }

        } catch (batchError) {
          // Log l·ªói batch nh∆∞ng kh√¥ng throw ƒë·ªÉ c√≥ th·ªÉ ti·∫øp t·ª•c
          logger.error(`‚îÇ  ‚ùå BATCH ${batchCount} ERROR:`, {
            message: batchError.message,
            stack: batchError.stack
          });
          
          // Throw l·ªói ƒë·ªÉ d·ª´ng migration
          throw new Error(`Batch ${batchCount} failed: ${batchError.message}`);
        }
      }

      // === T·ªîNG K·∫æT ===
      const totalDuration = ((Date.now() - startTime) / 1000).toFixed(2);
      
      logger.info('');
      logger.info('='.repeat(80));
      logger.info('‚úÖ MIGRATION HO√ÄN T·∫§T TH√ÄNH C√îNG');
      logger.info('‚îÄ'.repeat(80));
      logger.info(`‚îú‚îÄ Total Processed: ${totalProcessed}`);
      logger.info(`‚îú‚îÄ Total Inserted: ${totalInserted}`);
      logger.info(`‚îú‚îÄ Total Updated: ${totalUpdated}`);
      logger.info(`‚îú‚îÄ Total Batches: ${batchCount}`);
      logger.info(`‚îú‚îÄ Total Duration: ${totalDuration}s`);
      logger.info(`‚îî‚îÄ Avg per batch: ${(parseFloat(totalDuration) / batchCount).toFixed(2)}s`);
      logger.info('='.repeat(80));

      return {
        inserted: totalInserted,
        updated: totalUpdated,
        totalProcessed,
        batches: batchCount,
        duration: totalDuration
      };

    } catch (error) {
      const duration = ((Date.now() - startTime) / 1000).toFixed(2);
      
      logger.error('');
      logger.error('='.repeat(80));
      logger.error('‚ùå MIGRATION FAILED');
      logger.error('‚îÄ'.repeat(80));
      logger.error(`‚îú‚îÄ Error: ${error.message}`);
      logger.error(`‚îú‚îÄ Processed before error: ${totalProcessed}`);
      logger.error(`‚îú‚îÄ Inserted before error: ${totalInserted}`);
      logger.error(`‚îú‚îÄ Updated before error: ${totalUpdated}`);
      logger.error(`‚îú‚îÄ Batches completed: ${batchCount}`);
      logger.error(`‚îî‚îÄ Duration: ${duration}s`);
      logger.error('='.repeat(80));
      logger.error('Stack trace:', error.stack);

      // Re-throw ƒë·ªÉ controller x·ª≠ l√Ω
      throw error;
    }
  }

  /**
   * Rollback migration (n·∫øu c·∫ßn)
   * @param {Object} options - T√πy ch·ªçn rollback
   * @returns {Promise<Object>} K·∫øt qu·∫£ rollback
   */
  async rollback(options = {}) {
    try {
      if (!this.model) {
        throw new Error('Service ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o');
      }

      logger.info('[StreamOutgoingMigrationService] Starting rollback...');
      const result = await this.model.rollback(options);
      logger.info('[StreamOutgoingMigrationService] Rollback completed');

      return result;
    } catch (error) {
      logger.error('[StreamOutgoingMigrationService.rollback] Error:', error);
      throw error;
    }
  }
}

module.exports = StreamOutgoingMigrationService;